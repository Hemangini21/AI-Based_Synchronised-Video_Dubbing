

# ðŸŽ™ï¸ SYNCVOX:AI-Based Synchronized Video Dubbing

An AI-powered system that dubs videos into multiple languages while preserving **lip-sync**, **emotion**, and **voice consistency**. It automates the process using advanced ASR, translation, emotional TTS, and Wav2Lip for realistic synchronization.

---

## ðŸ“ Project Structure

```
AI-Based_Synchronised-Video_Dubbing/
â”‚
â”œâ”€â”€ backend/          # Core AI components (ASR, TTS, Wav2Lip, etc.)
â”œâ”€â”€ flask-api/        # Flask API backend to serve AI services
â”œâ”€â”€ frontend/         # UI for uploading videos and selecting language/emotion
â””â”€â”€ README.md         # Project documentation
```

---

## âš™ï¸ How It Works

```mermaid
graph TD
A[ðŸŽ¥ Input Video] --> B[ðŸ§  ASR (Speech-to-Text)]
B --> C[ðŸŒ Translation (MarianMT)]
C --> D[ðŸ—£ï¸ Emotional TTS (FastSpeech 2)]
D --> E[ðŸ‘„ Lip Sync with Wav2Lip]
E --> F[ðŸ“¼ Render Dubbing Output]
```

> The system breaks down input videos, transcribes speech, translates it, generates emotional speech, syncs lips to the new voice, and re-renders the video â€” all automatically.

---

## ðŸ”§ Tech Stack

| Layer      | Technology                           |
|------------|---------------------------------------|
| Frontend   | React+ Vite      |
| API Layer  | Flask (Python REST API)               |
| Backend    | PyTorch, OpenCV, FFmpeg               |
| AI Models  | Whisper, GTTS, FastSpeech2, Wav2Lip |

---
## ðŸ§ª Output Video


## ðŸ“š References

- [Wav2Lip (CVPR 2020)](https://github.com/Rudrabha/Wav2Lip)  
- [FastSpeech 2 (Microsoft Research)](https://arxiv.org/abs/2006.04558)  
- [Whisper by OpenAI](https://github.com/openai/whisper)  
